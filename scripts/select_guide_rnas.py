#!/usr/bin/env python3
# -*- coding: utf8 -*-
import argparse
import bisect
import gzip
import sys

from typing import Any, Dict, Iterator, List, Optional, Tuple
from collections import defaultdict

from typing_extensions import Literal
from mypy_extensions import TypedDict

try:
    import pysam
except ImportError as error:
    print("ERROR while importing Python module 'pysam':", file=sys.stderr)
    print("   ", error, file=sys.stderr)
    print("Please install module if it is not already installed!", file=sys.stderr)
    sys.exit(1)

Strand = Literal["+", "-"]

# PAM record generated by 'cryspyr'
PAM = TypedDict(
    "PAM",
    {
        "id": int,
        "contig": str,
        "cutsite": int,
        "strand": Strand,
        "seq": str,
        "start": int,
        "end": int,
        "score": int,
    },
)

Region = TypedDict(
    "Region",
    {
        # 1-based start site
        "start": int,
        # 1-based end site (inclusive)
        "end": int,
        # The number of bp in CDS prior to this CDS, taking strand into consideration
        "offset": int,
    },
)

MRNA = TypedDict(
    "MRNA",
    {
        # List of coding regions
        "CDS": List[Region],
        # Total length of all CDS
        "length": int,
        "start": int,
        "end": int,
    },
)

Gene = TypedDict(
    "Gene",
    {
        "id": str,
        "name": str,
        "dbxref": Optional[str],
        "strand": Strand,
        "contig": str,
        "start": int,
        "end": int,
        "mRNAs": Dict[str, MRNA],
    },
)

GeneMap = Dict[str, Gene]


def open_gff3(filename: str) -> Iterator[Any]:
    parser = pysam.asGFF3()
    with open(filename, "rb") as handle:
        for line in handle:
            if not line.startswith(b"#"):
                yield parser(line, len(line))


def process_mrna(mrna: MRNA, strand: Strand) -> None:
    cds = mrna["CDS"]
    cds.sort(key=lambda item: item["start"])

    if strand == "-":
        cds = cds[::-1]

    offset = 0
    for region in cds:
        region["offset"] = offset
        offset += region["end"] - region["start"]

    mrna["length"] = offset


##############################################################################


class GFF3Error(Exception):
    pass


class BEDError(Exception):
    pass


def read_gff3_gene(genes: GeneMap, record: Any) -> None:
    attributes = record.as_dict()
    record_id = attributes["ID"]  # FIXME: KeyError
    assert record_id not in genes  # FIXME

    genes[record_id] = {
        "id": record_id,
        "name": attributes.get("gene", record_id),
        "dbxref": attributes.get("Dbxref"),
        "strand": record.strand,
        "contig": record.contig,
        "start": record.start,
        "end": record.start,
        "mRNAs": {},
    }


def read_gff3_mrna(genes: GeneMap, mapping: Dict[str, str], record: Any) -> None:
    attributes = record.as_dict()
    record_id = attributes["ID"]  # FIXME: KeyError
    parent_id = attributes["Parent"]  # FIXME: KeyError

    if record_id in mapping:
        raise GFF3Error("duplicate mRNA %r" % (record_id,))
    elif parent_id not in genes:
        # mRNA did not belong to a 'gene' feature
        return

    # TODO: Compare strand/contig

    mapping[record_id] = parent_id
    genes[parent_id]["mRNAs"][record_id] = {
        "CDS": [],
        "length": 0,
        "start": record.start,
        "end": record.end,
    }  # FIXME: KeyError


def read_gff3_cds(genes: GeneMap, mapping: Dict[str, str], record: Any) -> None:
    attributes = record.as_dict()
    parent_id = attributes["Parent"]  # FIXME: KeyError

    # TODO: Compare strand/contig
    gene_id = mapping.get(parent_id)
    if gene_id is None:
        if parent_id not in genes:
            # CDS belonged to something other than a 'mRNA' or 'gene' feature
            return

        gene_id = parent_id
        # Create dummy mRNA record
        genes[gene_id]["mRNAs"].setdefault(
            parent_id,
            {
                "CDS": [],
                "length": 0,
            },
        )

    genes[gene_id]["mRNAs"][parent_id]["CDS"].append(
        {
            "start": record.start + 1,
            "end": record.end,
            "offset": 0,
        }
    )


def read_gff3(filename: str) -> GeneMap:
    genes: GeneMap = {}
    mapping: Dict[str, str] = {}  # mRNA ID to gene ID mapping

    for record in open_gff3(filename):
        if record.feature == "gene":
            read_gff3_gene(genes=genes, record=record)
        elif record.feature == "mRNA":
            read_gff3_mrna(genes=genes, mapping=mapping, record=record)
        elif record.feature == "CDS":
            read_gff3_cds(genes=genes, mapping=mapping, record=record)

    for gene in genes.values():
        for mrna in gene["mRNAs"].values():
            process_mrna(mrna, gene["strand"])

    return dict(genes)


def read_bed(filename: str) -> GeneMap:
    genes: GeneMap = {}
    with open(filename, "rt") as handle:
        for line in handle:
            fields = line.rstrip("\r\n").split("\t")
            if len(fields) < 4:
                raise BEDError("%r contains less than 4 columns" % (filename,))

            contig, start, end, name = fields[:4]

            strand = "+"
            if len(fields) >= 6:
                strand = fields[5]
                if strand not in ("+", "-"):
                    raise BEDError("invalid strand %r" % (strand,))

            try:
                gene = genes[name]
            except KeyError:
                gene = genes[name] = {
                    "id": name,
                    "name": name,
                    "dbxref": None,
                    "strand": strand,
                    "contig": contig,
                    "start": int(start),
                    "end": int(end),
                    "mRNAs": {name: {"length": 0, "CDS": []}},
                }

            gene["mRNAs"][name]["CDS"].append(
                {
                    "start": int(start) + 1,
                    "end": int(end),
                    "offset": 0,
                }
            )

    for gene in genes.values():
        for mrna in gene["mRNAs"].values():
            process_mrna(mrna, gene["strand"])

    return genes


def bisect_pams(pams: List[Tuple[int, PAM]], start: int, end: int) -> List[PAM]:
    left = bisect.bisect_left(pams, (start,))
    right = bisect.bisect_left(pams, (end + 1,))

    return [value for _, value in pams[left:right]]


def merge_regions(gene: Gene) -> List[Tuple[int, int]]:
    sorted_regions = []
    for record in gene["mRNAs"].values():
        for region in record["CDS"]:
            sorted_regions.append((region["start"], region["end"]))
    sorted_regions.sort()

    merged_regions = sorted_regions[:1]
    for start, end in sorted_regions[1:]:
        last_start, last_end = merged_regions[-1]

        if start - 1 <= last_end:
            merged_regions[-1] = (last_start, max(last_end, end))
        else:
            merged_regions.append((start, end))

    return merged_regions


def fetch_pams(handle: Any, gene: Gene, header: List[str]) -> List[Tuple[int, PAM]]:
    idx = 0
    pams: List[Tuple[int, PAM]] = []

    for start, end in merge_regions(gene):
        for line in handle.fetch(gene["contig"], start, end):
            data = dict(zip(header, line.rstrip().split("\t")))
            row: PAM = {
                "contig": data["Contig"],
                "cutsite": int(data["Cutsite"]),
                "strand": data["Strand"],
                "start": int(data["Start"]),
                "end": int(data["End"]),
                "seq": data["Sequence"],
                "score": int(data["Score"]),
                "id": idx,
            }

            pams.append((row["cutsite"], row))
            idx += 1

    return pams


def gc_content(seq: str) -> float:
    seq = seq.upper()
    ngc = seq.count("G") + seq.count("C")

    return ngc * 100.0 / len(seq)


def print_row(args: argparse.Namespace, gene: Gene, hit: PAM, rnas: Dict[str, float]):
    filters = []

    # 1. All splice variants should be targeted by gRNA
    cds = []
    for key, _ in sorted(gene["mRNAs"].items(), key=lambda it: it[1]["start"]):
        cds.append("|" if key in rnas else "-")

    if "-" in cds:
        filters.append("mRNAs")

    # 2. Four or more Ts act as a terminator
    #    Note that the PAM (in lowercase) cannot trigger this filter
    if "TTTT" in hit["seq"]:
        filters.append("TTTT")

    # 3. Recommended GC content is 40 to 80%; add some leeway
    gc_pct = gc_content(hit["seq"])
    if gc_pct < args.min_gc_content:
        filters.append("lGC")
    elif gc_pct > args.max_gc_content:
        filters.append("hGC")

    # 4. The majority of the CDS should be downstream of cutsite
    if min(rnas.values()) < args.min_coverage:
        filters.append("lCov")

    min_distance_to_termini = float("inf")
    for rna in rnas:
        for region in gene["mRNAs"][rna]["CDS"]:
            if region["start"] <= hit["cutsite"] <= region["end"]:
                distance_to_5p = hit["cutsite"] - region["start"]
                distance_to_3p = region["end"] - hit["cutsite"]

                min_distance_to_termini = min(
                    min_distance_to_termini, distance_to_5p, distance_to_3p
                )

    return {
        "Gene": (gene["name"], gene["contig"], gene["strand"], gene["start"]),
        "Name": (gene["name"], gene["contig"], hit["strand"], hit["cutsite"]),
        "Contig": gene["contig"],
        "Start": hit["start"],
        "End": hit["end"],
        "Cutsite": hit["cutsite"],
        "Strand": hit["strand"],
        "Sequence": hit["seq"],
        "Score": hit["score"],
        "PctCov": min(rnas.values()),
        "PctGC": gc_pct,
        "TerminiDist": min_distance_to_termini,
        "Filters": frozenset(filters),
        "CDS": "".join(cds),
    }


def build_filtered_rows(args, gene, pams_by_id, sorted_hits):
    rows_with_full_overlap = []
    rows_with_partial_overlap = []

    def _sort_rows(rows):
        rows.sort(key=lambda it: it[args.sort_by], reverse=args.sort_by_reverse)

    for pam_id, rnas in sorted_hits:
        hit = pams_by_id[pam_id]
        row = print_row(args, gene, hit, rnas)

        filters = row["Filters"]
        if args.print_all or not filters:
            rows_with_full_overlap.append(row)
        elif "mRNAs" in filters and not filters - frozenset(("mRNAs",)):
            rows_with_partial_overlap.append(row)

    _sort_rows(rows_with_full_overlap)
    _sort_rows(rows_with_partial_overlap)

    if args.missing_cds == "allow":
        rows = rows_with_full_overlap + rows_with_partial_overlap
        # Must be sorted here to allow picking top hits
        _sort_rows(rows)
    elif args.missing_cds == "fallback":
        if not rows_with_full_overlap:
            rows = rows_with_partial_overlap
        elif args.candidates_per_target > len(rows_with_full_overlap):
            n_fallbacks = args.candidates_per_target - len(rows_with_full_overlap)
            # Not sorted here, to ensure that fully overlapping hits are retained
            rows = rows_with_full_overlap + rows_with_partial_overlap[:n_fallbacks]
        else:
            rows = rows_with_full_overlap
    else:
        assert args.missing_cds == "filter", args.missing_cds
        rows = rows_with_full_overlap

    if args.candidates_per_target > 0 and len(rows) >= args.candidates_per_target:
        rows = rows[: args.candidates_per_target]

    _sort_rows(rows)
    return rows


class ArgumentHelpFormatter(argparse.ArgumentDefaultsHelpFormatter):
    def _fill_text(self, text, width, indent):
        return "".join(indent + line for line in text.splitlines(keepends=True))


def parse_args(argv: List[str]) -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        formatter_class=ArgumentHelpFormatter,
        description="Locate and filter CRISPyR gRNAs targeting genes listed in a GFF "
        "file or genomic regions listed in a BED file.\n\n"
        "The output from CRISPyR `find` is expected to be `tabix` index:"
        "  $ crispyr find ... | bgzip > candidates.tsv.gz\n"
        "  $ tabix -S 1 -s 2 -b 5 -e 5 candidates.tsv.gz\n"
        "  $ select_guide_rnas.py --crispyr candidates.tsv.gz ...\n\n"
        "If CRISPyR was run using the `--bed` argument, slightly different tabix "
        "parameters are required:\n"
        "  $ crispyr find --bed ... | bgzip > candidates.tsv.gz\n"
        "  $ tabix -S 1 -s 3 -b 6 -e 6 candidates.tsv.gz\n"
        "  $ select_guide_rnas.py --crispyr candidates.tsv.gz ...\n\n"
        "Note that the regions in the BED file passed to CRISPyR should be unique and "
        "non-overlapping for `tabix` to be albe to properly index the file.",
    )

    parser.add_argument(
        "--gff",
        metavar="FILE",
        help="GFF file containing annotations for protein coding genes",
    )
    parser.add_argument(
        "--bed",
        metavar="FILE",
        help="BED file containing named genomic regions",
    )
    parser.add_argument(
        "--crispyr",
        metavar="FILE",
        required=True,
        help="Tabix indexed output from Crispyr 'find'",
    )
    parser.add_argument(
        "--min-coverage",
        metavar="PCT",
        default=50.0,
        type=float,
        help="Minimum %% of CDS downstream of cutsite",
    )
    parser.add_argument(
        "--min-gc-content",
        metavar="PCT",
        default=35.0,
        type=float,
        help="Minimum %% GC in gRNA sequences",
    )
    parser.add_argument(
        "--max-gc-content",
        metavar="PCT",
        default=85.0,
        type=float,
        help="Maximum %% GC in gRNA sequences",
    )
    parser.add_argument(
        "--print-all",
        default=False,
        action="store_true",
        help="Also print hits that failed one or more quality filters",
    )
    parser.add_argument(
        "--sort-by",
        default="Score",
        type=str.title,
        help="Sort per-gene results using this column",
    )
    parser.add_argument(
        "--candidates-per-target",
        default=0,
        type=int,
        help="Print at most N guide RNAs per target; 0 or less prints everything",
    )
    parser.add_argument(
        "--missing-cds",
        default="filter",
        choices=("filter", "allow", "fallback"),
        help="Either 'filter' candidates that don't cut all coding sequences, 'allow' "
        "them, or 'fallback' to such candidates only if there are no candidates or "
        "not enough candidates per --candidates-per-target. Not applicable if "
        "--print-all is set",
    )

    return parser.parse_args(argv)


def main(argv: List[str]) -> int:
    args = parse_args(argv)

    genes = []
    if args.gff is not None:
        genes.extend(read_gff3(args.gff).values())

    if args.bed is not None:
        genes.extend(read_bed(args.bed).values())

    if not genes:
        print(
            "ERROR: No genes or genomic regions were specified with --gff or --bed. "
            "Please provide a GFF file containing target genes and/or a BED file "
            "containing targets regions.",
            file=sys.stderr,
        )
        return 1

    header = [
        ("Gene", lambda it: "%s_%s%s%i" % it),
        ("Name", lambda it: "%s_%s%s%i" % it),
        ("Contig", str),
        ("Start", str),
        ("End", str),
        ("Cutsite", str),
        ("Strand", str),
        ("Sequence", str),
        ("Score", str),
        ("PctCov", lambda it: "%.1f" % (it,)),
        ("PctGC", lambda it: "%.1f" % (it,)),
        ("TerminiDist", str),
        ("Filters", lambda it: ";".join(sorted(it)) or "."),
    ]

    if args.missing_cds in ("allow", "fallback") or args.print_all:
        header.append(("CDS", str))

    print("\t".join(key for key, _ in header))

    args.sort_by_reverse = False
    if args.sort_by.startswith("-"):
        args.sort_by_reverse = True
        args.sort_by = args.sort_by[1:]

    for key, _ in header:
        if key.lower() == args.sort_by.lower():
            args.sort_by = key
            break
    else:
        print("Unknown sort-by column %r", file=sys.stderr)
        return 1

    total_hits = 0
    printed_hits = 0

    with gzip.open(args.crispyr, "rt") as handle:
        crispyr_header = handle.readline().rstrip().split("\t")

    with pysam.TabixFile(args.crispyr) as handle:
        for gene in sorted(genes, key=lambda it: it["name"].lower()):
            pams = fetch_pams(handle, gene, crispyr_header)
            pams_by_id = {pam["id"]: pam for _, pam in pams}

            hits: Dict[int, Dict[str, float]] = defaultdict(dict)
            for mrna_name, mrna in gene["mRNAs"].items():
                for region in mrna["CDS"]:
                    for pam in bisect_pams(pams, region["start"], region["end"]):
                        if gene["strand"] == "+":
                            bp_downstream = (
                                region["offset"] + pam["cutsite"] - region["start"]
                            )
                        elif gene["strand"] == "-":
                            bp_downstream = (
                                region["offset"] + region["end"] - pam["cutsite"]
                            )

                        hits[pam["id"]][mrna_name] = (
                            100.0 - bp_downstream * 100.0 / mrna["length"]
                        )

            sorted_hits: List[Tuple[int, Dict[str, float]]] = sorted(hits.items())
            total_hits += len(sorted_hits)

            if gene["strand"] == "-":
                sorted_hits = sorted_hits[::-1]

            rows = build_filtered_rows(args, gene, pams_by_id, sorted_hits)
            for row in rows:
                print("\t".join(func(row[key]) for key, func in header))

            if not rows:
                print("# No hits found for %s (%s)" % (gene["id"], gene["name"]))

            printed_hits += len(rows)

            print()

    print("Printed %i of %i hits" % (printed_hits, total_hits), file=sys.stderr)

    return 0


if __name__ == "__main__":
    sys.exit(main(sys.argv[1:]))
